{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_CA5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahdifarhang/AI_CA5/blob/master/AI_CA5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbCVuQPeUXJo",
        "colab_type": "text"
      },
      "source": [
        "# **گزارش کار تمرین کامپیوتری پنجم درس هوش مصنوعی**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejKQkT6jWy8x",
        "colab_type": "text"
      },
      "source": [
        "# سوال اول"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WpFOxZ7mGnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3Bf3dgtmGnn",
        "colab_type": "code",
        "outputId": "f7747664-846d-47a9-a28c-c85a23b13814",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor()])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksCT0xMTmGns",
        "colab_type": "text"
      },
      "source": [
        "1. Define a Convolution Neural Network\n",
        "\n",
        "here we define our neural network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-BY9_XDmGns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxTpy91eXURb",
        "colab_type": "text"
      },
      "source": [
        "## با وزن های تصادفی "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XX8ENlRrNiS_",
        "colab_type": "code",
        "outputId": "70b46ddb-b153-4450-a288-552f134984a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "torch.nn.init.xavier_uniform_(net.conv1.weight)\n",
        "torch.nn.init.xavier_uniform_(net.conv2.weight)\n",
        "torch.nn.init.xavier_uniform_(net.fc1.weight)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.1035,  0.1174,  0.0942,  ..., -0.1038, -0.0324,  0.0116],\n",
              "        [-0.0154,  0.0285, -0.0126,  ...,  0.0056,  0.0538,  0.0255],\n",
              "        [ 0.1059, -0.1133,  0.0189,  ..., -0.1028,  0.0050,  0.0533],\n",
              "        ...,\n",
              "        [-0.1060, -0.0621, -0.1131,  ...,  0.0804, -0.0519,  0.0149],\n",
              "        [ 0.0232,  0.1187, -0.0443,  ...,  0.0157,  0.0144,  0.0457],\n",
              "        [-0.0270, -0.1112,  0.0625,  ...,  0.0074,  0.1119, -0.1076]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgu1IzD2mGnx",
        "colab_type": "text"
      },
      "source": [
        "2. Define a Loss function and optimizer\n",
        "\n",
        "\n",
        "\n",
        "Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYlYectjZ7I-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRFE-SyvmGnz",
        "colab_type": "text"
      },
      "source": [
        "3. Train the network\n",
        "\n",
        "We simply have to loop over our data iterator, and feed the inputs to the\n",
        "network and optimize.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf4j0iX_Z7YK",
        "colab_type": "code",
        "outputId": "921c65c6-bee2-42f1-edf3-638ddf5780b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 500 == 499:    # print every 500 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 500))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 1.589\n",
            "[1,  1000] loss: 1.572\n",
            "[1,  1500] loss: 1.546\n",
            "[2,   500] loss: 1.514\n",
            "[2,  1000] loss: 1.492\n",
            "[2,  1500] loss: 1.472\n",
            "[3,   500] loss: 1.438\n",
            "[3,  1000] loss: 1.432\n",
            "[3,  1500] loss: 1.409\n",
            "[4,   500] loss: 1.379\n",
            "[4,  1000] loss: 1.394\n",
            "[4,  1500] loss: 1.366\n",
            "[5,   500] loss: 1.350\n",
            "[5,  1000] loss: 1.346\n",
            "[5,  1500] loss: 1.334\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFw8puxKmGn3",
        "colab_type": "text"
      },
      "source": [
        "4. Test the network on the test data\n",
        "\n",
        "\n",
        "We have trained the network for 2 passes over the training dataset.\n",
        "But we need to check if the network has learnt anything at all.\n",
        "\n",
        "We will check this by predicting the class label that the neural network\n",
        "outputs, and checking it against the ground-truth. If the prediction is\n",
        "correct, we add the sample to the list of correct predictions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFIPYpNIZ7gu",
        "colab_type": "code",
        "outputId": "981fe9dc-be44-474d-9933-6e8d4b11e9ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 52 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mlxyeTQbVGX",
        "colab_type": "text"
      },
      "source": [
        "به دست آمد که دقت داده های تست ما بر روی ۱۰۰۰ داده برابر 52 درصد است. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV4QS1DKc7gi",
        "colab_type": "text"
      },
      "source": [
        "## با وزن های صفر:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTxZJoIiOSu4",
        "colab_type": "code",
        "outputId": "3cecf11b-f3bb-4179-f880-5d1bd7ec81b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "torch.nn.init.zeros_(net.conv1.bias)\n",
        "torch.nn.init.zeros_(net.conv1.weight)\n",
        "torch.nn.init.zeros_(net.conv2.bias)\n",
        "torch.nn.init.zeros_(net.conv2.weight)\n",
        "torch.nn.init.zeros_(net.fc1.bias)\n",
        "torch.nn.init.zeros_(net.fc1.weight)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE-_THt6mGnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BxGvvRumGn0",
        "colab_type": "code",
        "outputId": "c36cee44-6720-4d85-b3ec-4ceb13e7477e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 500 == 499:    # print every 500 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 500))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 2.303\n",
            "[1,  1000] loss: 2.303\n",
            "[1,  1500] loss: 2.303\n",
            "[2,   500] loss: 2.303\n",
            "[2,  1000] loss: 2.303\n",
            "[2,  1500] loss: 2.303\n",
            "[3,   500] loss: 2.303\n",
            "[3,  1000] loss: 2.303\n",
            "[3,  1500] loss: 2.303\n",
            "[4,   500] loss: 2.303\n",
            "[4,  1000] loss: 2.303\n",
            "[4,  1500] loss: 2.303\n",
            "[5,   500] loss: 2.303\n",
            "[5,  1000] loss: 2.303\n",
            "[5,  1500] loss: 2.303\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o43RFaZweBQR",
        "colab_type": "text"
      },
      "source": [
        "همانطور که مشاهده میشود، خطا طی تمرین های متوالی و بیشتر کم نمیشود. که البته این مسئله طبیعی به نظر میرسد و ما این را پیشبینی میکردیم.\n",
        "علت این است که چون ضرایب صفر است، تمرین های قبلی تاثیری را به وجود نمی آورد."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Do6aTeHmGoC",
        "colab_type": "code",
        "outputId": "e1ab3340-ed1e-4b36-932d-f92e1bb6ba55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 10 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYLrxKOvmGoE",
        "colab_type": "text"
      },
      "source": [
        "این بار دقت ما به ۱۰ درصد کاهش پیدا کرد.و این عدد نیز قابل پیشبینی بود. یعنی کاملا رندوم تشخیص داده است.(چون ۱۰نوع خروجی داریم) و این مسئله طبیعی است چون آموزش (همانطور که دیده شد) انجام نمیشود."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57Rv2f83e36W",
        "colab_type": "text"
      },
      "source": [
        "بدیهی است که وزن های رندوم نتیجه ی بهتری به ما میدهد"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSjFZ3cqfFMY",
        "colab_type": "text"
      },
      "source": [
        "# سوال دوم"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1sieyKqfuBp",
        "colab_type": "text"
      },
      "source": [
        "یک convolution layar از  network خود کم میکنیم"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VissjFHHu3C4",
        "colab_type": "text"
      },
      "source": [
        "## Conv2d(3, 8, 5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IgHa5SC0feRv",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 8, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(8 * 14 * 14, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "#         print(x.size())\n",
        "        x = x.view(-1, 8 * 14 * 14)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tsjpFgVLvIdm"
      },
      "source": [
        "برای پیدا کردن عدد ۱۴ که در کد نوشته شده، بعد از کانوالو در تابع فوروارد، مقدار اندازه ایکس را چاپ میکنیم\n",
        "یک آرایه ی چهار تایی میگیریم که سه عدد نهایی آن همان عددی است که باید به ورودی تابع خطی داده شود.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1f617563-ee22-4c27-fcd7-d62d8830dff1",
        "id": "-_fxMyw6vIdp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "torch.nn.init.xavier_uniform_(net.conv1.weight)\n",
        "torch.nn.init.xavier_uniform_(net.fc1.weight)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0149,  0.0327,  0.0576,  ...,  0.0049,  0.0163, -0.0131],\n",
              "        [-0.0466,  0.0394, -0.0262,  ...,  0.0403, -0.0639, -0.0224],\n",
              "        [-0.0399, -0.0035,  0.0675,  ...,  0.0345, -0.0606,  0.0317],\n",
              "        ...,\n",
              "        [ 0.0061, -0.0708,  0.0649,  ...,  0.0484, -0.0608, -0.0127],\n",
              "        [-0.0458,  0.0252,  0.0254,  ...,  0.0465, -0.0679, -0.0312],\n",
              "        [ 0.0117,  0.0260,  0.0681,  ...,  0.0178,  0.0545,  0.0615]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G0nBc9_KvIdx",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4ac4047c-57b5-45d7-d609-b829cf02a8e2",
        "id": "pu1x41iXvId2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 500 == 499:    # print every 500 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 500))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 2.133\n",
            "[1,  1000] loss: 1.920\n",
            "[1,  1500] loss: 1.837\n",
            "[2,   500] loss: 1.762\n",
            "[2,  1000] loss: 1.689\n",
            "[2,  1500] loss: 1.682\n",
            "[3,   500] loss: 1.637\n",
            "[3,  1000] loss: 1.627\n",
            "[3,  1500] loss: 1.603\n",
            "[4,   500] loss: 1.587\n",
            "[4,  1000] loss: 1.569\n",
            "[4,  1500] loss: 1.575\n",
            "[5,   500] loss: 1.545\n",
            "[5,  1000] loss: 1.547\n",
            "[5,  1500] loss: 1.533\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "de5c48a8-28fb-44e0-9538-cc7a8b612dfe",
        "id": "tSyJ4-XRvIeB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 49 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nexz_p4pvIeL"
      },
      "source": [
        "همانطور که انتظار میرفت، دقت داده های ما از ۵۲ به 49 کاهش پیدا کرد. این کاهش طبیعی است زیرا یک لایه از لایه های شبکه عصبی ما کم شده است و دقت خروجی ما طبیعتا کاهش پیدا میکند.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkr6K4EMvQoz",
        "colab_type": "text"
      },
      "source": [
        "## Conv2d(3, 6, 5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84Fvz4shuYC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(6 * 14 * 14, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "#         print(x.size())\n",
        "        x = x.view(-1, 6 * 14 * 14)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OUv7AxUnKIZ",
        "colab_type": "text"
      },
      "source": [
        "برای پیدا کردن عدد ۱۴ که در کد نوشته شده، بعد از کانوالو در تابع فوروارد، مقدار اندازه ایکس را چاپ میکنیم\n",
        "یک آرایه ی چهار تایی میگیریم که سه عدد نهایی آن همان عددی است که باید به ورودی تابع خطی داده شود.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1f617563-ee22-4c27-fcd7-d62d8830dff1",
        "id": "YvhehHTqgo3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "torch.nn.init.xavier_uniform_(net.conv1.weight)\n",
        "torch.nn.init.xavier_uniform_(net.fc1.weight)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0149,  0.0327,  0.0576,  ...,  0.0049,  0.0163, -0.0131],\n",
              "        [-0.0466,  0.0394, -0.0262,  ...,  0.0403, -0.0639, -0.0224],\n",
              "        [-0.0399, -0.0035,  0.0675,  ...,  0.0345, -0.0606,  0.0317],\n",
              "        ...,\n",
              "        [ 0.0061, -0.0708,  0.0649,  ...,  0.0484, -0.0608, -0.0127],\n",
              "        [-0.0458,  0.0252,  0.0254,  ...,  0.0465, -0.0679, -0.0312],\n",
              "        [ 0.0117,  0.0260,  0.0681,  ...,  0.0178,  0.0545,  0.0615]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4rFBWul9go3n",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4ac4047c-57b5-45d7-d609-b829cf02a8e2",
        "id": "-Zax84M5go3r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 500 == 499:    # print every 500 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 500))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 2.133\n",
            "[1,  1000] loss: 1.920\n",
            "[1,  1500] loss: 1.837\n",
            "[2,   500] loss: 1.762\n",
            "[2,  1000] loss: 1.689\n",
            "[2,  1500] loss: 1.682\n",
            "[3,   500] loss: 1.637\n",
            "[3,  1000] loss: 1.627\n",
            "[3,  1500] loss: 1.603\n",
            "[4,   500] loss: 1.587\n",
            "[4,  1000] loss: 1.569\n",
            "[4,  1500] loss: 1.575\n",
            "[5,   500] loss: 1.545\n",
            "[5,  1000] loss: 1.547\n",
            "[5,  1500] loss: 1.533\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b2d62e28-c147-4a30-a911-24512e2885f5",
        "id": "92Juag6Bgo32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 46 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD800jMmnvEs",
        "colab_type": "text"
      },
      "source": [
        "همانطور که انتظار میرفت، دقت داده های ما از ۵۲ به 46 کاهش پیدا کرد. این کاهش طبیعی است زیرا یک لایه از لایه های شبکه عصبی ما کم شده است و دقت خروجی ما طبیعتا کاهش پیدا میکند.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvLW3RJQvX7u",
        "colab_type": "text"
      },
      "source": [
        "در دو حالت مختلفی که سوال دو را حل کردیم، دقت ما ۴۹ و ۴۶ درصد بود. نتیجه میگیریم که تعداد لایه هایی که از کانولوشن خروجی میگیریم اگر از ۶ به ۸ تغییر پیدا کند، دقت از ۴۶ به ۴۹ ارتقا پیدا میکند."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4B_bPNvoS2b",
        "colab_type": "text"
      },
      "source": [
        "# سوال سوم"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j0rTeWcpzxQ",
        "colab_type": "code",
        "outputId": "d43b8132-97b3-4221-fab4-e32f4d5c6ae9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6MyPSCOqUrm",
        "colab_type": "text"
      },
      "source": [
        "در بالا در خط سوم داده ها را نرمالایز میکنیم"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-aCf2nVp5EX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnaXgU_wqRR3",
        "colab_type": "code",
        "outputId": "07ecfbf2-95a9-48c5-d6a2-a696292c92ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "torch.nn.init.xavier_uniform_(net.conv1.weight)\n",
        "torch.nn.init.xavier_uniform_(net.conv2.weight)\n",
        "torch.nn.init.xavier_uniform_(net.fc1.weight)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0167,  0.0850,  0.0664,  ...,  0.1204, -0.0475, -0.1047],\n",
              "        [-0.0271,  0.1160, -0.1066,  ...,  0.0061,  0.0729, -0.0980],\n",
              "        [ 0.0537, -0.0613,  0.0829,  ..., -0.0144,  0.0497,  0.0131],\n",
              "        ...,\n",
              "        [-0.1171,  0.0554, -0.0911,  ..., -0.0267,  0.0892, -0.0805],\n",
              "        [-0.0376, -0.0833,  0.0991,  ...,  0.0561, -0.0865,  0.0752],\n",
              "        [-0.0505,  0.1084,  0.0548,  ..., -0.0945, -0.0487,  0.0605]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOUaK6dwqnpB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66tCY9kCqrL3",
        "colab_type": "code",
        "outputId": "84048f90-7d45-4b50-adb4-803858252e2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 500 == 499:    # print every 500 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 500))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 2.116\n",
            "[1,  1000] loss: 1.795\n",
            "[1,  1500] loss: 1.669\n",
            "[2,   500] loss: 1.591\n",
            "[2,  1000] loss: 1.531\n",
            "[2,  1500] loss: 1.503\n",
            "[3,   500] loss: 1.450\n",
            "[3,  1000] loss: 1.443\n",
            "[3,  1500] loss: 1.403\n",
            "[4,   500] loss: 1.372\n",
            "[4,  1000] loss: 1.358\n",
            "[4,  1500] loss: 1.350\n",
            "[5,   500] loss: 1.318\n",
            "[5,  1000] loss: 1.304\n",
            "[5,  1500] loss: 1.295\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdKsPIlfqsFw",
        "colab_type": "code",
        "outputId": "f997dc45-85dd-4330-b575-aa0ce0dabc5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 54 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eu6qvKFsWhS",
        "colab_type": "text"
      },
      "source": [
        "با مقایسه ی زمان تمرین داده های نرمالایز نشده (که برابر است با ۱۰۷ ثانیه) و داده های نرمالایز شده (که برابر است با 116 ثانیه) متوجه میشویم که زمان ها  متفاوت اند و تمرین داده های نرمال شده بیشتر طول میکشد.\n",
        "دقت ها را که مقایسه میکنیم میبینیم که دقت تخمین در داده های نرمال 54 درصد و در داده های غیر نرمال ۵۲ درصد است که خب دقیق تر تخمین زده است.\n",
        "\n",
        " بدیهی است که پروسه ی نرمالایز  کردن، هیچ ارتباطی به برچسب ها نداشته باشد. زیرا ما داریم داده ها و در واقع تصاویر را به گونه ای نرمال میکنیم و همه ی آنها بعد از نرمال شدن همان برچسب قبلی را بدون هیچ تغییری خواهند داشت و معنا ندارد که در نرمال کردن تصاویر، برچسب ها تغییری کنند."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE5u6zPEwsTw",
        "colab_type": "text"
      },
      "source": [
        "# سوال چهارم"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HYRsh8lxI1E",
        "colab_type": "text"
      },
      "source": [
        "## high learning rate = 0.01"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swQBs8X7wvUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkDn1vGm10cb",
        "colab_type": "code",
        "outputId": "93640375-fa7b-4d90-ed78-3cba91e63459",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list_of_loses = []\n",
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        list_of_loses.append(loss.item())\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 500 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tw3jtDW3xQqn",
        "colab_type": "code",
        "outputId": "14f1710d-6800-4569-ec48-6987f6c8cbd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 56 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIYZVlqI79r4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dUQkbk10l85",
        "colab_type": "code",
        "outputId": "c2ea6bf7-5785-480a-d09b-4b715c9dc9a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "x = np.array(range(len(list_of_loses)))\n",
        "plt.plot(x, list_of_loses)\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w86ybQ+WG6TQwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8MAkAqL0dGE",
        "colab_type": "text"
      },
      "source": [
        "## normal learning rate = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPXWgyyD14Rb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8tjz4xr0U4A",
        "colab_type": "code",
        "outputId": "6fa1793a-892b-467f-c54f-87d9a425a69d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "list_of_loses = []\n",
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        list_of_loses.append(loss.item())\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 500 == 499:    # print every 500 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 500))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 1.031\n",
            "[1,  1000] loss: 0.999\n",
            "[1,  1500] loss: 1.003\n",
            "[2,   500] loss: 0.973\n",
            "[2,  1000] loss: 0.973\n",
            "[2,  1500] loss: 0.978\n",
            "[3,   500] loss: 0.952\n",
            "[3,  1000] loss: 0.961\n",
            "[3,  1500] loss: 0.968\n",
            "[4,   500] loss: 0.947\n",
            "[4,  1000] loss: 0.961\n",
            "[4,  1500] loss: 0.948\n",
            "[5,   500] loss: 0.943\n",
            "[5,  1000] loss: 0.947\n",
            "[5,  1500] loss: 0.947\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJKT5vnt1Vd_",
        "colab_type": "code",
        "outputId": "133b138e-eb78-41a5-da6d-24caf210c3f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 64 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yEGIb0n1WLl",
        "colab_type": "code",
        "outputId": "26001277-d755-4b76-dec0-949043b7d584",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "x = np.array(range(len(list_of_loses)))\n",
        "plt.plot(x, list_of_loses)\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-QWY_MX263vr"
      },
      "source": [
        "## low learning rate = 0.00001"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z40mggG063vv",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.00001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "89A9gh4E63vz",
        "outputId": "f0062343-56b5-42db-c6ae-3a96e96eff33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "list_of_loses = []\n",
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        list_of_loses.append(loss.item())\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 500 == 499:    # print every 500 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 500))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 0.926\n",
            "[1,  1000] loss: 0.914\n",
            "[1,  1500] loss: 0.910\n",
            "[2,   500] loss: 0.910\n",
            "[2,  1000] loss: 0.920\n",
            "[2,  1500] loss: 0.914\n",
            "[3,   500] loss: 0.915\n",
            "[3,  1000] loss: 0.912\n",
            "[3,  1500] loss: 0.916\n",
            "[4,   500] loss: 0.915\n",
            "[4,  1000] loss: 0.903\n",
            "[4,  1500] loss: 0.924\n",
            "[5,   500] loss: 0.915\n",
            "[5,  1000] loss: 0.911\n",
            "[5,  1500] loss: 0.907\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QuDV9F4T63v2",
        "outputId": "f8a04279-1203-43c8-9259-3137892879c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 64 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gaG-4eNb63v5",
        "outputId": "20f315e9-e78c-4957-ab49-3071c8abacef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "x = np.array(range(len(list_of_loses)))\n",
        "plt.plot(x, list_of_loses)\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8doam49J8nh",
        "colab_type": "text"
      },
      "source": [
        "از مهم ترین نتایجی که میگیریم این است که مقدار زیاد لرنینگ ریت به هیچ وجه به نفع ما نیست و اگر آنرا زیاد کنیم به شدت ضرر میکنیم. اما با کم کردن آن، حال به مقدار یک صدم آن، تفاوت چندانی در دقت مشاهده نمیشود. \n",
        "\n",
        "نتیجه ی دیگری که میگیریم این است که با افزایش لرنینگ ریت، کم شدن خطا در طول زمان (افزایش داده تمرینی) بیشتر مشاهده میشود. یعنی برای کم شدن خطا در طی زیاد شدن داده های تمرینی، زیاد بودن لرنینگ ریت مناسب است "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-7ojLfO8fkj",
        "colab_type": "text"
      },
      "source": [
        "# سوال پنجم"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xgSCtex8j-G",
        "colab_type": "text"
      },
      "source": [
        "## batch size = 64"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "98f6aca7-ff77-4b31-83ad-9166a1110999",
        "id": "7eCLqKgX9VVq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bn7kqc2K9VV0",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "40d3930f-98ae-4ad4-86d0-294e2672aab1",
        "id": "VSZR-2T99VV9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "torch.nn.init.xavier_uniform_(net.conv1.weight)\n",
        "torch.nn.init.xavier_uniform_(net.conv2.weight)\n",
        "torch.nn.init.xavier_uniform_(net.fc1.weight)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.1060, -0.0719, -0.0082,  ..., -0.0568,  0.1013, -0.1180],\n",
              "        [ 0.1178,  0.0429,  0.1091,  ..., -0.0614,  0.0645, -0.0240],\n",
              "        [-0.0761,  0.0241,  0.0169,  ..., -0.0195,  0.0976, -0.0032],\n",
              "        ...,\n",
              "        [ 0.0225, -0.0467, -0.0065,  ..., -0.0659, -0.0819, -0.1079],\n",
              "        [ 0.0681,  0.0150,  0.0377,  ..., -0.0289,  0.0047,  0.0638],\n",
              "        [ 0.0801,  0.0348,  0.0057,  ...,  0.0548,  0.0634, -0.0787]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7kU4lE8X9VWA",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4d1c1046-8f75-456d-984d-5b059bbc7b0f",
        "id": "mvB-ByMM9VWD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 500 == 499:    # print every 500 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 500))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 2.172\n",
            "[2,   500] loss: 1.777\n",
            "[3,   500] loss: 1.604\n",
            "[4,   500] loss: 1.513\n",
            "[5,   500] loss: 1.455\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "806475d0-c889-4854-a3b7-1ef722936914",
        "id": "1AGMFJTs9VWG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 48 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o72fDKFh-_Kh"
      },
      "source": [
        "## batch size = 256"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "28af9a27-605b-45b2-b1d0-46ba138651cd",
        "id": "HoVOXp6R-_Kl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=256,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NglEW5aK-_Ko",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8a6c5fc6-fe2d-4788-989f-b29b2e5f49c3",
        "id": "LJZysjXR-_Kq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "torch.nn.init.xavier_uniform_(net.conv1.weight)\n",
        "torch.nn.init.xavier_uniform_(net.conv2.weight)\n",
        "torch.nn.init.xavier_uniform_(net.fc1.weight)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0933,  0.0970, -0.1011,  ..., -0.0822,  0.0487, -0.0441],\n",
              "        [ 0.0493,  0.0942, -0.0766,  ...,  0.0957, -0.1071,  0.0864],\n",
              "        [ 0.0043,  0.0052, -0.0085,  ...,  0.0818,  0.0033,  0.0902],\n",
              "        ...,\n",
              "        [ 0.0330, -0.0087, -0.0356,  ...,  0.0923, -0.0445,  0.0649],\n",
              "        [-0.0432, -0.0146,  0.0526,  ..., -0.0928,  0.0341, -0.0349],\n",
              "        [-0.0972,  0.0085, -0.0555,  ...,  0.0651,  0.0918,  0.1049]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wfQDPXht-_Kv",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3b8f8d8d-546c-4667-fc41-14f5cf9ff971",
        "id": "SxeyVmcg-_Kw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 500 == 499:    # print every 500 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 500))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5127b72a-3dfb-4408-c433-cf0740cffe15",
        "id": "QwZM79Pj-_K0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 39 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEkvVrooAxgF",
        "colab_type": "text"
      },
      "source": [
        "همانطور که مشاهده شد، با افزایش بچ سایز از ۳۲ به ۶۴ دقت ما از ۵۲ به 48 کاهش پیدا میکند و با کاهش آن از ۶۴ به ۲۵۶ ، دقت ما از 48 درصد به 39 درصد کاهش پیدا کرد. نتیجه ای که میگیریم این است که اگر بچ سایز را بدون دست زدن به لرنینگ ریت افزایش دهیم، دقت تخمین کاهش میابد\n",
        "برتری ای که ما در افزایش بچ سایز به دست می آوریم، افزایش سرعت داده های تمرینی است.این نتیجه نیز قابل پیشبینی بود، زیرا دسته ها بزرگتر هستند و طبقه بندی بزرگتر سرعت ما را افزایش میدهد. \n",
        "(کاهش زمان از 116 به ۹۹ و به 84(\n",
        "."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVoJFsnT_SGk",
        "colab_type": "text"
      },
      "source": [
        "### increase learning rate 10 times"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e60Xd7Vt_iJW",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "553431f6-e850-4e3f-e236-ecfe438996be",
        "id": "P_4_-Qsl_iJc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 500 == 499:    # print every 500 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 500))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6d43c636-1b7f-484e-bb75-a0f45a1cfa86",
        "id": "eoAzUpVG_iJq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 55 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SA1UteSO_q5A"
      },
      "source": [
        "### decrease learning rate 10 times"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6zu0Ksit_q5D",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XkUnJqpa_q5Q",
        "outputId": "1950db18-5b6b-4847-ab5a-5a86f96e7512",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 500 == 499:    # print every 500 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 500))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bfc71f61-43bc-4c7a-dffc-f5e81efbb673",
        "id": "T25ACUKn_q5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 57 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYsogdtjBWTC",
        "colab_type": "text"
      },
      "source": [
        "حال میبینیم که با دست زدن به لرنینگ ریت، دقت افزایش پیدا میکند. اما حال که بچ سایز را زیاد کرده ایم، با کاهش دادن لرنینگ ریت میتوانیم دقت بیشتری را منتظر باشیم تا با افزایش دادن آن. یعنی در نهایت کاهش لرنینگ ریت به نفع ما تمام میشود"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fv9cJvrwCHrm",
        "colab_type": "text"
      },
      "source": [
        "# سوال ششم"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a70316ef-ce09-4383-be8e-852ebac87254",
        "id": "UXukKXusEzcm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMvpQqEhFCPx",
        "colab_type": "text"
      },
      "source": [
        "## tanh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "afZUZU1xEzcu",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.tanh(self.conv1(x)))\n",
        "        x = self.pool(F.tanh(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7e2471a3-4f36-4529-f454-4cf852978ced",
        "id": "_ImQoTBxEzc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "torch.nn.init.xavier_uniform_(net.conv1.weight)\n",
        "torch.nn.init.xavier_uniform_(net.conv2.weight)\n",
        "torch.nn.init.xavier_uniform_(net.fc1.weight)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.1107, -0.0714, -0.1042,  ..., -0.0766, -0.0651,  0.0210],\n",
              "        [-0.0221, -0.0179, -0.0767,  ...,  0.0604,  0.0632, -0.1163],\n",
              "        [-0.0414, -0.0500,  0.0972,  ...,  0.0260,  0.0399, -0.0242],\n",
              "        ...,\n",
              "        [-0.0506, -0.0493,  0.0938,  ...,  0.1044,  0.0803,  0.0249],\n",
              "        [-0.0066, -0.0958,  0.0857,  ...,  0.0089,  0.0901,  0.0377],\n",
              "        [-0.0873, -0.0466, -0.0707,  ...,  0.1186,  0.0371,  0.0703]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 291
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LrnhQpLXEzc8",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "05d100e0-cdb6-4ab2-a591-eab3f80dffb9",
        "id": "YztZWdG5EzdD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 500 == 499:    # print every 500 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 500))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 2.025\n",
            "[1,  1000] loss: 1.785\n",
            "[1,  1500] loss: 1.667\n",
            "[2,   500] loss: 1.583\n",
            "[2,  1000] loss: 1.556\n",
            "[2,  1500] loss: 1.525\n",
            "[3,   500] loss: 1.482\n",
            "[3,  1000] loss: 1.458\n",
            "[3,  1500] loss: 1.443\n",
            "[4,   500] loss: 1.412\n",
            "[4,  1000] loss: 1.393\n",
            "[4,  1500] loss: 1.365\n",
            "[5,   500] loss: 1.338\n",
            "[5,  1000] loss: 1.345\n",
            "[5,  1500] loss: 1.312\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c5b8515a-b587-43d8-f398-259e5b8f9063",
        "id": "PjQMOWurEzdG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 53 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tezETQ7pFYIs"
      },
      "source": [
        "## leaky_relu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JRkMjyjrFYIu",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.leaky_relu(self.conv1(x)))\n",
        "        x = self.pool(F.leaky_relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "55e31783-7146-48f0-902e-5b0e185caadd",
        "id": "pfOTYZNxFYIz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "torch.nn.init.xavier_uniform_(net.conv1.weight)\n",
        "torch.nn.init.xavier_uniform_(net.conv2.weight)\n",
        "torch.nn.init.xavier_uniform_(net.fc1.weight)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0805, -0.0810, -0.0173,  ...,  0.1023,  0.0349, -0.0632],\n",
              "        [ 0.0229,  0.0931,  0.1203,  ..., -0.0494, -0.0457,  0.0419],\n",
              "        [-0.1096,  0.0349,  0.0723,  ...,  0.0334, -0.0676,  0.1099],\n",
              "        ...,\n",
              "        [-0.0835, -0.0559,  0.0663,  ...,  0.0492, -0.0718,  0.0110],\n",
              "        [ 0.0240,  0.0574,  0.0913,  ..., -0.0146,  0.0799, -0.1026],\n",
              "        [-0.0024, -0.0019,  0.0739,  ..., -0.0717, -0.0264, -0.0098]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 296
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KCRD_eTrFYI7",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cbaa7b12-c3a5-4784-992b-5cbbc1cf729b",
        "id": "K9XgIk7-FYI-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 500 == 499:    # print every 500 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 500))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 2.093\n",
            "[1,  1000] loss: 1.820\n",
            "[1,  1500] loss: 1.669\n",
            "[2,   500] loss: 1.572\n",
            "[2,  1000] loss: 1.525\n",
            "[2,  1500] loss: 1.496\n",
            "[3,   500] loss: 1.457\n",
            "[3,  1000] loss: 1.420\n",
            "[3,  1500] loss: 1.411\n",
            "[4,   500] loss: 1.369\n",
            "[4,  1000] loss: 1.355\n",
            "[4,  1500] loss: 1.349\n",
            "[5,   500] loss: 1.308\n",
            "[5,  1000] loss: 1.305\n",
            "[5,  1500] loss: 1.284\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "75f538a6-d462-4132-f9a3-a0235535cf13",
        "id": "HB1IDLT5FYJB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 54 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MAOYLhHpGBXD"
      },
      "source": [
        "## softplus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Inw2Wk4MGBXF",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.softplus(self.conv1(x)))\n",
        "        x = self.pool(F.softplus(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5c78208a-659f-4051-fbb6-75d75237c8dd",
        "id": "R9NubRj6GBXI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "torch.nn.init.xavier_uniform_(net.conv1.weight)\n",
        "torch.nn.init.xavier_uniform_(net.conv2.weight)\n",
        "torch.nn.init.xavier_uniform_(net.fc1.weight)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.1157,  0.1070,  0.0532,  ..., -0.0891,  0.0280, -0.0180],\n",
              "        [ 0.0673, -0.0411, -0.0520,  ...,  0.1020,  0.0199,  0.0419],\n",
              "        [ 0.0690, -0.1033, -0.0422,  ...,  0.0076,  0.0164,  0.0672],\n",
              "        ...,\n",
              "        [ 0.0345,  0.1185,  0.0309,  ...,  0.1028, -0.0532,  0.0448],\n",
              "        [ 0.1169,  0.0087, -0.0560,  ...,  0.0066, -0.0228,  0.0910],\n",
              "        [-0.0041, -0.1093,  0.0452,  ..., -0.0262, -0.0504,  0.0995]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 301
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DE8U3VD5GBXM",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a0821f74-f5e5-4621-e3b3-363938f51e8f",
        "id": "aJ3XM022GBXP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 500 == 499:    # print every 500 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 500))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 2.285\n",
            "[1,  1000] loss: 2.078\n",
            "[1,  1500] loss: 1.917\n",
            "[2,   500] loss: 1.789\n",
            "[2,  1000] loss: 1.719\n",
            "[2,  1500] loss: 1.670\n",
            "[3,   500] loss: 1.612\n",
            "[3,  1000] loss: 1.591\n",
            "[3,  1500] loss: 1.559\n",
            "[4,   500] loss: 1.529\n",
            "[4,  1000] loss: 1.515\n",
            "[4,  1500] loss: 1.500\n",
            "[5,   500] loss: 1.464\n",
            "[5,  1000] loss: 1.460\n",
            "[5,  1500] loss: 1.441\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e8ff8d53-802f-4b2c-9686-cc5b4abc848e",
        "id": "auso9QteGBXY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 48 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqe1L783MAYN",
        "colab_type": "text"
      },
      "source": [
        "نتیجه میگیریم که بهترین \n",
        "activation function\n",
        "از بین توابع گفته شده\n",
        "relu\n",
        "و \n",
        "leaku_relu\n",
        "هستند"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNUY-iooMi19",
        "colab_type": "text"
      },
      "source": [
        "# سوال هفتم"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "45cb4914-4b32-4b0f-86b6-6302db9227ed",
        "id": "TPNg4hy_Mqfn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a9D5agG6Mqfx",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "dbfa4ac5-f635-49c9-95c8-e7a873fbce4e",
        "id": "wwKN34w-Mqf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "torch.nn.init.xavier_uniform_(net.conv1.weight)\n",
        "torch.nn.init.xavier_uniform_(net.conv2.weight)\n",
        "torch.nn.init.xavier_uniform_(net.fc1.weight)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.1055,  0.0954, -0.1014,  ..., -0.0333, -0.0583, -0.0636],\n",
              "        [ 0.0893,  0.0664,  0.1071,  ..., -0.0970,  0.0084,  0.0734],\n",
              "        [ 0.1165, -0.0450,  0.0469,  ..., -0.1168,  0.1153,  0.0772],\n",
              "        ...,\n",
              "        [ 0.0491, -0.1197, -0.0008,  ..., -0.0997, -0.0728, -0.0473],\n",
              "        [-0.0222, -0.0512, -0.0329,  ..., -0.0636, -0.0025, -0.0587],\n",
              "        [ 0.1205, -0.0201, -0.0874,  ..., -0.0212, -0.0204,  0.0528]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 315
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pevjaVYM7_i",
        "colab_type": "text"
      },
      "source": [
        "## with momentum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ONWMrJJtMqgF",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ac5a6563-b439-431f-99f7-965c1a2ce4fa",
        "id": "jjw9rl4eMqgK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 500 == 499:    # print every 500 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 500))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 2.063\n",
            "[1,  1000] loss: 1.823\n",
            "[1,  1500] loss: 1.708\n",
            "[2,   500] loss: 1.624\n",
            "[2,  1000] loss: 1.561\n",
            "[2,  1500] loss: 1.527\n",
            "[3,   500] loss: 1.464\n",
            "[3,  1000] loss: 1.464\n",
            "[3,  1500] loss: 1.433\n",
            "[4,   500] loss: 1.383\n",
            "[4,  1000] loss: 1.380\n",
            "[4,  1500] loss: 1.357\n",
            "[5,   500] loss: 1.323\n",
            "[5,  1000] loss: 1.303\n",
            "[5,  1500] loss: 1.294\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6f8d2ef7-6760-4af6-b141-c77d624964f0",
        "id": "BmaLbiX1MqgO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 53 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LI29JsZHNArZ"
      },
      "source": [
        "## without momentum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LoEB9a40NArc",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b9e263da-5613-4efc-dc28-afc200695e68",
        "id": "0zPoYIfGNArj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 500 == 499:    # print every 500 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 500))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 2.297\n",
            "[1,  1000] loss: 2.258\n",
            "[1,  1500] loss: 2.216\n",
            "[2,   500] loss: 2.141\n",
            "[2,  1000] loss: 2.072\n",
            "[2,  1500] loss: 2.013\n",
            "[3,   500] loss: 1.970\n",
            "[3,  1000] loss: 1.960\n",
            "[3,  1500] loss: 1.917\n",
            "[4,   500] loss: 1.902\n",
            "[4,  1000] loss: 1.860\n",
            "[4,  1500] loss: 1.854\n",
            "[5,   500] loss: 1.825\n",
            "[5,  1000] loss: 1.783\n",
            "[5,  1500] loss: 1.791\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6fbe5add-bb76-4338-b7c5-5a0ce1caa3bf",
        "id": "SIBn2oymNArx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 37 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVMnzt2xPK0G",
        "colab_type": "text"
      },
      "source": [
        "مشاهده شد که از لحاظ زمانی تفاوت خاصی بین دو حالت گفته شده وجود ندارد.\n",
        "اما تفاوت اصلی در دقت تخمین است که حالت با استفاده از مومنتوم بسیار بهتر است.\n",
        "\n",
        "علت به این گونه است:\n",
        "وقتی که داریم محاسبه میکنیم، در بخشی از کارمان، دقت به گونه ای است که در یک \n",
        "local minima \n",
        "گیر کرده ایم و فک میکنیم که به حالت ایده آل رسیده ایم\n",
        "اگر این مشکل برای ما ایجاد شد، با وجود موممنتوم های زیاد میتوانیم از این لوکال مینیما ها خارج شویم\n",
        "طبیعی است که اگر اندازه ی مومنتوم بیش از حد زیاد باشد، تلاش بیش از حد زیادی برای خروج از لوکال مینیما انجام میشود که الزاما خوب نیست.\n",
        "به عکس های درون لینک زیر میتوان دقت کرد\n",
        "https://www.quora.com/What-does-momentum-mean-in-neural-networks\n"
      ]
    }
  ]
}